{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification of Issues.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Classification of Issues**"
      ],
      "metadata": {
        "id": "FdXiwjtkt6XK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning Project on Github Issues**\n",
        "\n",
        "Github Issue Classification\n",
        "\n",
        "\n",
        "*   Predicting if Github Issue is a Bug, Enhancement or Question."
      ],
      "metadata": {
        "id": "IgBzz7bRek9S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucd3RduYcmhr"
      },
      "outputs": [],
      "source": [
        "## Data Collection\n",
        "#!wget https://github.com/niranjana1997/Classification-of-Issues-on-Github/blob/main/github-labels-top3-34k.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing neattext library\n",
        "!pip install neattext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjnHT-Npr8nd",
        "outputId": "b6916637-8de7-4cd4-bac7-aa24641d6fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neattext\n",
            "  Downloading neattext-0.1.2-py3-none-any.whl (114 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 30 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 40 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 51 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 61 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 71 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 81 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 92 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 102 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 112 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 114 kB 3.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: neattext\n",
            "Successfully installed neattext-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import pandas as pd # for data analysis\n",
        "import neattext.functions as nfx # for text cleaning\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "FbL_5CzdfIq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Dataset\n",
        "df_csv = pd.read_csv('dataset/github-labels-top3-34k.csv', header=None, sep=',')"
      ],
      "metadata": {
        "id": "5wBuVFtofLh0",
        "outputId": "f5b43568-b3bb-4095-91a3-cbf5b3efd222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9a65e3de2d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/github-labels-top3-34k.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/github-labels-top3-34k.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv.head()"
      ],
      "metadata": {
        "id": "ZG4jTVmqUz62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset preparation\n",
        "+ extract the labels from the csv file\n",
        "    - enhancement|bug|question"
      ],
      "metadata": {
        "id": "xwPp-Z1rjq8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv = df_csv[0].str.split(r'(__label__enhancement)|(__label__bug)|(__label__question)', expand=True)\n",
        "#df_csv"
      ],
      "metadata": {
        "id": "g7ZoqRsdjqhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating three data frames for each label\n",
        "enhancement_df = df_csv[df_csv[1] == '__label__enhancement'][[1,4]]\n",
        "bug_df = df_csv[df_csv[2] == '__label__bug'][[2,4]]\n",
        "question_df = df_csv[df_csv[3] == '__label__question'][[3,4]]"
      ],
      "metadata": {
        "id": "9qMGjsz9j0uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding column names to the dataframes\n",
        "enhancement_df.columns = ['label','description']\n",
        "bug_df.columns = ['label','description']\n",
        "question_df.columns = ['label','description']"
      ],
      "metadata": {
        "id": "TlgOp7T_j8Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concat Dataframes\n",
        "final_df = pd.concat([enhancement_df, bug_df, question_df])"
      ],
      "metadata": {
        "id": "isUjvAmhkaur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing prefix __label__\n",
        "final_df['label'] = final_df['label'].str.replace('__label__', '')"
      ],
      "metadata": {
        "id": "PJPJE_yVkgy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving dataframe to csv file\n",
        "final_df.to_csv(\"final_dataframe.csv\")"
      ],
      "metadata": {
        "id": "94ubhRzDkiUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head()"
      ],
      "metadata": {
        "id": "2MKNV_FnU6HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Distribution Analysis"
      ],
      "metadata": {
        "id": "wHfy2-GVX9tW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "7Hiyvrcyncxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x = 'label', data = final_df)"
      ],
      "metadata": {
        "id": "0qvdjkLMYDF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stopwords and converting the text into lower case\n",
        "final_df['desc_clean'] = final_df['description'].apply(lambda x: nfx.remove_stopwords(str(x).lower()))"
      ],
      "metadata": {
        "id": "DEFx2aIqogOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head()"
      ],
      "metadata": {
        "id": "S6izm1T0CBMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-test split"
      ],
      "metadata": {
        "id": "yCG17WqUdkp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(final_df['desc_clean'],final_df['label'],test_size=0.3,random_state=42)"
      ],
      "metadata": {
        "id": "yvFkbkMDrlY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model building**\n",
        "\n",
        "**DecisionTreeClassifier - Naive Bayes - Logistic Regression**\n",
        "\n",
        "These algorithms is used to build the issue classification model.\n",
        "\n",
        "**Count Vectorizer**\n",
        "\n",
        "This package enables machine learning models to understand the text. Machines learning models have a problem of understanding and using raw texts. However, machine learning models work well with numbers.\n",
        "\n",
        "CountVectorizer converts the raw text into vectors of numbers. It ensures that the converted vectors of numbers represent the original text."
      ],
      "metadata": {
        "id": "7nD3ELknvja3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing machine learning packages\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "5bAdzZr7sZUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Pipeline package automates all the stages and processes used in building the model."
      ],
      "metadata": {
        "id": "x38CO1YKxLlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Pipeline package\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "tlR66pyIvcDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To automate the process of a model building using this Pipeline package, we initialize all the stages in building the model. After initializing the stages, they will be automated.\n",
        "\n",
        "We have two stages as follows:\n",
        "\n",
        "1.   CountVectorizer converting the input text to vectors of numbers.\n",
        "2.   Using the DecisionTreeClassifier, Naive Bayes, Logistic Regression & Random forest algorithms to train the model."
      ],
      "metadata": {
        "id": "e7maQ3jdy1gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making pipeline\n",
        "pipeLine_nb = Pipeline(steps=[('cv', CountVectorizer()), ('nb', MultinomialNB())])\n",
        "pipeLine_lr = Pipeline(steps=[('cv', CountVectorizer()), ('lr', LogisticRegression())])\n",
        "pipeLine_dt = Pipeline(steps=[('cv', CountVectorizer()), ('dt', DecisionTreeClassifier())])\n",
        "pipeLine_rf = Pipeline(steps=[('cv', CountVectorizer()), ('rf', RandomForestClassifier())])"
      ],
      "metadata": {
        "id": "dbL1NSiByzCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build actual model - Naive Bayes\n",
        "pipeLine_nb.fit(x_train, y_train)\n",
        "y_pred_nb = pipeLine_nb.predict(x_test)\n",
        "print(classification_report(y_test,y_pred_nb))"
      ],
      "metadata": {
        "id": "WBxvTyZP_VpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build actual model - DecisionTreeClassifier\n",
        "pipeLine_dt.fit(x_train, y_train)\n",
        "y_pred_dt = pipeLine_dt.predict(x_test)\n",
        "print(classification_report(y_test,y_pred_dt))"
      ],
      "metadata": {
        "id": "403yBy1l_kiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build actual model - Logistic Regression\n",
        "pipeLine_lr.fit(x_train, y_train)\n",
        "pipeLine_lr.score(x_test, y_test)\n",
        "y_pred_lr = pipeLine_lr.predict(x_test)\n",
        "print(classification_report(y_test,y_pred_lr))"
      ],
      "metadata": {
        "id": "euYZmexQ_tdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build actual model - Random Forest\n",
        "pipeLine_rf.fit(x_train, y_train)\n",
        "y_pred_rf = pipeLine_rf.predict(x_test)\n",
        "print(classification_report(y_test,y_pred_rf))"
      ],
      "metadata": {
        "id": "3ZhKNA9GeRkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "# Source: https://github.com/streamlit/streamlit/issues\n",
        "# Bug - Keras load_img is not working if i display any image on the top of the page\n",
        "# Enhancement - Feature request: Slider: negative space and histograms\n",
        "# Question - Number Input Scientific Format\n",
        "test1 = \"Keras load_img is not working if i display any image on the top of the page\"\n",
        "test2 = \"Feature request: Slider: negative space and histograms\"\n",
        "test3 = \"Number Input Scientific Format\""
      ],
      "metadata": {
        "id": "kzyTRu9H_7_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making prediction - Naive Bayes - Bug\n",
        "pipeLine_nb.predict([test1])"
      ],
      "metadata": {
        "id": "RGcg_gbXAbB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making prediction - Naive Bayes - Enhancement\n",
        "pipeLine_nb.predict([test2])"
      ],
      "metadata": {
        "id": "GCft0YbhAr56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making prediction - Naive Bayes - Question\n",
        "pipeLine_nb.predict([test3])"
      ],
      "metadata": {
        "id": "ordJAOxpAuoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making prediction - DecisionTreeClassifier - Bug\n",
        "pipeLine_dt.predict([test1])"
      ],
      "metadata": {
        "id": "kdv8imQLAxiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making prediction - DecisionTreeClassifier - Enhancement\n",
        "pipeLine_dt.predict([test2])"
      ],
      "metadata": {
        "id": "Phjwzvf2A5NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making prediction - DecisionTreeClassifier - Question\n",
        "pipeLine_dt.predict([test3])"
      ],
      "metadata": {
        "id": "hMBmwRNrA9Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making prediction - Logistic Regression - Bug\n",
        "pipeLine_dt.predict([test1])"
      ],
      "metadata": {
        "id": "bw8D7pqSBAHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making prediction - Logistic Regression - Enhancement\n",
        "pipeLine_dt.predict([test2])"
      ],
      "metadata": {
        "id": "lKfA9qyzBF4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making prediction - Logistic Regression - Question\n",
        "pipeLine_dt.predict([test3])"
      ],
      "metadata": {
        "id": "zpewp1PeBILO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s8iMkZfU9wIE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}